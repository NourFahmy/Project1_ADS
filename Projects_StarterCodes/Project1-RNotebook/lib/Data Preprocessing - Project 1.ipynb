{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee656a28",
   "metadata": {},
   "source": [
    "This notebook takes you through my preprocessing process. I had to make sure the columns I will want to use, namely tokenized_txt, are in a format I can use as well as remove stopwords especially topic-relevant stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f00650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>school</th>\n",
       "      <th>sentence_spacy</th>\n",
       "      <th>sentence_str</th>\n",
       "      <th>original_publication_date</th>\n",
       "      <th>corpus_edition_date</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>sentence_lowered</th>\n",
       "      <th>tokenized_txt</th>\n",
       "      <th>lemmatized_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>What's new, Socrates, to make you leave your ...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>125</td>\n",
       "      <td>what's new, socrates, to make you leave your ...</td>\n",
       "      <td>['what', 'new', 'socrates', 'to', 'make', 'you...</td>\n",
       "      <td>what be new , Socrates , to make -PRON- lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>Surely you are not prosecuting anyone before t...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>69</td>\n",
       "      <td>surely you are not prosecuting anyone before t...</td>\n",
       "      <td>['surely', 'you', 'are', 'not', 'prosecuting',...</td>\n",
       "      <td>surely -PRON- be not prosecute anyone before ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>The Athenians do not call this a prosecution b...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>74</td>\n",
       "      <td>the athenians do not call this a prosecution b...</td>\n",
       "      <td>['the', 'athenians', 'do', 'not', 'call', 'thi...</td>\n",
       "      <td>the Athenians do not call this a prosecution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>What is this you say?</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>21</td>\n",
       "      <td>what is this you say?</td>\n",
       "      <td>['what', 'is', 'this', 'you', 'say']</td>\n",
       "      <td>what be this -PRON- say ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plato - Complete Works</td>\n",
       "      <td>Plato</td>\n",
       "      <td>plato</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>Someone must have indicted you, for you are no...</td>\n",
       "      <td>-350</td>\n",
       "      <td>1997</td>\n",
       "      <td>101</td>\n",
       "      <td>someone must have indicted you, for you are no...</td>\n",
       "      <td>['someone', 'must', 'have', 'indicted', 'you',...</td>\n",
       "      <td>someone must have indict -PRON- , for -PRON- ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title author school  \\\n",
       "0  Plato - Complete Works  Plato  plato   \n",
       "1  Plato - Complete Works  Plato  plato   \n",
       "2  Plato - Complete Works  Plato  plato   \n",
       "3  Plato - Complete Works  Plato  plato   \n",
       "4  Plato - Complete Works  Plato  plato   \n",
       "\n",
       "                                      sentence_spacy  \\\n",
       "0   What's new, Socrates, to make you leave your ...   \n",
       "1  Surely you are not prosecuting anyone before t...   \n",
       "2  The Athenians do not call this a prosecution b...   \n",
       "3                              What is this you say?   \n",
       "4  Someone must have indicted you, for you are no...   \n",
       "\n",
       "                                        sentence_str  \\\n",
       "0   What's new, Socrates, to make you leave your ...   \n",
       "1  Surely you are not prosecuting anyone before t...   \n",
       "2  The Athenians do not call this a prosecution b...   \n",
       "3                              What is this you say?   \n",
       "4  Someone must have indicted you, for you are no...   \n",
       "\n",
       "   original_publication_date  corpus_edition_date  sentence_length  \\\n",
       "0                       -350                 1997              125   \n",
       "1                       -350                 1997               69   \n",
       "2                       -350                 1997               74   \n",
       "3                       -350                 1997               21   \n",
       "4                       -350                 1997              101   \n",
       "\n",
       "                                    sentence_lowered  \\\n",
       "0   what's new, socrates, to make you leave your ...   \n",
       "1  surely you are not prosecuting anyone before t...   \n",
       "2  the athenians do not call this a prosecution b...   \n",
       "3                              what is this you say?   \n",
       "4  someone must have indicted you, for you are no...   \n",
       "\n",
       "                                       tokenized_txt  \\\n",
       "0  ['what', 'new', 'socrates', 'to', 'make', 'you...   \n",
       "1  ['surely', 'you', 'are', 'not', 'prosecuting',...   \n",
       "2  ['the', 'athenians', 'do', 'not', 'call', 'thi...   \n",
       "3               ['what', 'is', 'this', 'you', 'say']   \n",
       "4  ['someone', 'must', 'have', 'indicted', 'you',...   \n",
       "\n",
       "                                      lemmatized_str  \n",
       "0     what be new , Socrates , to make -PRON- lea...  \n",
       "1   surely -PRON- be not prosecute anyone before ...  \n",
       "2   the Athenians do not call this a prosecution ...  \n",
       "3                          what be this -PRON- say ?  \n",
       "4   someone must have indict -PRON- , for -PRON- ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/nour/OneDrive/Documents/STAT 5243/project 1/philosophy_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5154fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "df['tokenized_txt'] = df['tokenized_txt'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51cc17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##what are some common words of each school?\n",
    "import numpy as np\n",
    "schools_grouped = df.groupby('school')['tokenized_txt'].agg(list)\n",
    "##grouped text -- have to find what the most common words and phrases are of each school\n",
    "df1 = pd.DataFrame(schools_grouped)\n",
    "df1['tokenized_txt'] = df1['tokenized_txt'].apply(lambda x: list(np.concatenate(x).flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6c6d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nour\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ef9a3",
   "metadata": {},
   "source": [
    "Evaluating more stopwords by looking at each school's stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "024863e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one', 6151), ('would', 4537), ('may', 3782), ('say', 3526), ('true', 3055), ('sense', 2518), ('case', 2381), ('might', 2223), ('theory', 2138), ('two', 2135), ('also', 2055), ('even', 2033), ('must', 2001), ('know', 1943), ('way', 1915), ('us', 1868), ('language', 1853), ('world', 1835), ('fact', 1831), ('time', 1826), ('different', 1747), ('truth', 1715), ('certain', 1712), ('think', 1709), ('like', 1581), ('something', 1524), ('could', 1522), ('see', 1491), ('question', 1491), ('possible', 1457), ('first', 1382), ('given', 1377), ('whether', 1290), ('things', 1286), ('cannot', 1266), ('belief', 1251), ('another', 1248), ('statements', 1247), ('use', 1245), ('sentence', 1242), ('meaning', 1222), ('proposition', 1218), ('example', 1215), ('thing', 1186), ('words', 1170), ('word', 1167), ('knowledge', 1167), ('thus', 1151), ('make', 1134), ('terms', 1127)]\n",
      "[('one', 9543), ('must', 4482), ('things', 4461), ('also', 4344), ('man', 4125), ('thing', 2905), ('good', 2627), ('animals', 2508), ('may', 2448), ('another', 2393), ('time', 2379), ('case', 2305), ('two', 2296), ('either', 2259), ('like', 2164), ('part', 2154), ('body', 2058), ('first', 2054), ('say', 2048), ('nature', 2047), ('something', 2039), ('since', 2032), ('would', 2027), ('way', 2004), ('others', 1986), ('motion', 1912), ('therefore', 1910), ('parts', 1857), ('water', 1819), ('said', 1785), ('many', 1667), ('every', 1665), ('reason', 1647), ('even', 1590), ('place', 1589), ('kind', 1545), ('men', 1530), ('eg', 1477), ('possible', 1440), ('sense', 1440), ('cannot', 1426), ('whether', 1356), ('always', 1354), ('without', 1344), ('number', 1310), ('movement', 1307), ('animal', 1306), ('true', 1299), ('air', 1299), ('called', 1269)]\n",
      "[('would', 2960), ('price', 2328), ('upon', 2210), ('money', 1906), ('labour', 1786), ('value', 1767), ('great', 1758), ('capital', 1648), ('may', 1613), ('part', 1597), ('country', 1597), ('one', 1571), ('quantity', 1514), ('produce', 1506), ('greater', 1318), ('interest', 1306), ('much', 1289), ('must', 1258), ('trade', 1208), ('therefore', 1202), ('rate', 1115), ('land', 1105), ('different', 1070), ('every', 1030), ('wages', 965), ('rent', 957), ('could', 950), ('corn', 934), ('tax', 930), ('whole', 920), ('employment', 919), ('though', 909), ('either', 902), ('time', 895), ('goods', 889), ('people', 850), ('two', 840), ('proportion', 821), ('however', 820), ('demand', 820), ('might', 817), ('market', 813), ('commodities', 811), ('less', 806), ('stock', 778), ('increase', 766), ('revenue', 747), ('silver', 738), ('employed', 727), ('profits', 725)]\n",
      "[('labour', 3311), ('value', 2508), ('one', 1771), ('capital', 1547), ('production', 1453), ('power', 1095), ('time', 1050), ('work', 1027), ('form', 926), ('working', 914), ('means', 908), ('day', 890), ('social', 887), ('capitalist', 848), ('money', 847), ('therefore', 760), ('state', 749), ('commodities', 736), ('would', 715), ('must', 697), ('hours', 690), ('surplus', 685), ('commodity', 663), ('first', 651), ('may', 609), ('class', 609), ('process', 583), ('part', 575), ('hand', 561), ('also', 557), ('two', 542), ('every', 536), ('industry', 533), ('labourer', 528), ('number', 522), ('political', 519), ('workers', 498), ('even', 497), ('use', 495), ('factory', 492), ('great', 478), ('without', 478), ('whole', 478), ('society', 471), ('new', 470), ('machinery', 470), ('product', 463), ('necessary', 450), ('fact', 432), ('wages', 432)]\n",
      "[('one', 4144), ('madness', 2283), ('would', 1965), ('form', 1913), ('language', 1630), ('time', 1624), ('must', 1531), ('order', 1528), ('within', 1501), ('first', 1466), ('difference', 1449), ('two', 1434), ('nature', 1414), ('even', 1400), ('without', 1398), ('man', 1367), ('thought', 1362), ('also', 1130), ('representation', 1101), ('possible', 1096), ('knowledge', 1091), ('world', 1069), ('sense', 1068), ('relation', 1061), ('could', 1046), ('new', 1018), ('us', 1016), ('forms', 1013), ('body', 1011), ('history', 1011), ('century', 1008), ('reason', 1006), ('always', 995), ('truth', 972), ('another', 962), ('longer', 954), ('point', 950), ('way', 930), ('social', 917), ('upon', 912), ('question', 899), ('general', 894), ('repetition', 872), ('fact', 860), ('desire', 855), ('like', 851), ('system', 846), ('rather', 840), ('life', 833), ('since', 809)]\n",
      "[('ideas', 3486), ('one', 3209), ('may', 2696), ('idea', 2385), ('us', 1980), ('mind', 1942), ('men', 1580), ('without', 1552), ('must', 1488), ('man', 1416), ('things', 1270), ('would', 1258), ('upon', 1229), ('though', 1214), ('reason', 1189), ('nature', 1174), ('make', 1167), ('yet', 1139), ('another', 1138), ('every', 1090), ('therefore', 1075), ('first', 1002), ('power', 990), ('nothing', 943), ('knowledge', 920), ('certain', 902), ('cannot', 901), ('shall', 899), ('objects', 880), ('different', 876), ('two', 861), ('think', 825), ('object', 824), ('never', 822), ('much', 814), ('use', 810), ('great', 799), ('part', 794), ('body', 791), ('made', 773), ('thing', 772), ('particular', 770), ('existence', 769), ('general', 743), ('matter', 723), ('present', 711), ('either', 711), ('time', 703), ('find', 693), ('parts', 692)]\n",
      "[('woman', 3125), ('women', 3071), ('man', 1870), ('one', 1700), ('men', 1216), ('would', 1018), ('life', 1005), ('love', 986), ('even', 826), ('like', 806), ('black', 758), ('mother', 713), ('often', 684), ('world', 668), ('male', 639), ('husband', 616), ('also', 597), ('many', 593), ('must', 582), ('without', 574), ('girl', 560), ('little', 548), ('first', 547), ('time', 543), ('never', 532), ('children', 523), ('could', 520), ('young', 499), ('child', 498), ('white', 465), ('still', 462), ('sexual', 458), ('thus', 450), ('work', 447), ('always', 445), ('body', 434), ('wife', 433), ('female', 428), ('two', 422), ('human', 412), ('every', 406), ('make', 398), ('people', 397), ('well', 392), ('less', 383), ('great', 376), ('marriage', 375), ('reason', 372), ('made', 372), ('nature', 372)]\n",
      "[('one', 7082), ('concept', 4299), ('self', 3833), ('reason', 3634), ('nature', 3434), ('also', 3346), ('consciousness', 3224), ('would', 3155), ('therefore', 3073), ('object', 2973), ('something', 2814), ('must', 2754), ('first', 2694), ('thus', 2653), ('pure', 2584), ('form', 2525), ('existence', 2511), ('unity', 2211), ('time', 2200), ('since', 2124), ('even', 2112), ('universal', 2020), ('merely', 1962), ('law', 1946), ('determination', 1924), ('world', 1862), ('content', 1858), ('however', 1815), ('way', 1771), ('nothing', 1745), ('general', 1696), ('us', 1680), ('thing', 1644), ('understanding', 1630), ('thought', 1613), ('without', 1603), ('absolute', 1594), ('possible', 1581), ('relation', 1574), ('two', 1561), ('means', 1542), ('cognition', 1518), ('cannot', 1517), ('subject', 1508), ('given', 1497), ('principle', 1489), ('may', 1483), ('latter', 1459), ('things', 1443), ('yet', 1432)]\n",
      "[('one', 1899), ('man', 1068), ('thou', 867), ('even', 838), ('ye', 694), ('life', 680), ('also', 648), ('must', 633), ('zarathustra', 626), ('would', 606), ('god', 581), ('every', 577), ('good', 550), ('like', 524), ('things', 523), ('great', 491), ('world', 478), ('still', 466), ('however', 459), ('men', 442), ('thus', 427), ('love', 422), ('upon', 413), ('us', 408), ('may', 405), ('hath', 396), ('thy', 394), ('time', 389), ('say', 389), ('people', 381), ('unto', 366), ('first', 362), ('spirit', 351), ('thee', 347), ('everything', 345), ('day', 340), ('self', 332), ('soul', 329), ('much', 323), ('ever', 312), ('truth', 300), ('become', 297), ('well', 296), ('many', 291), ('means', 291), ('new', 290), ('long', 289), ('old', 289), ('last', 285), ('whole', 284)]\n",
      "[('world', 4351), ('one', 2764), ('time', 1813), ('way', 1802), ('dasein', 1635), ('must', 1536), ('consciousness', 1522), ('us', 1496), ('beings', 1391), ('sense', 1387), ('present', 1368), ('knowledge', 1368), ('things', 1274), ('experience', 1255), ('something', 1252), ('thus', 1230), ('even', 1223), ('first', 1218), ('object', 1188), ('self', 1163), ('meaning', 1151), ('body', 1099), ('life', 1091), ('truth', 1042), ('already', 1018), ('science', 1009), ('also', 999), ('thing', 986), ('within', 952), ('possible', 946), ('always', 925), ('subject', 918), ('essence', 877), ('means', 866), ('fact', 848), ('existence', 840), ('thought', 829), ('would', 819), ('perception', 814), ('hand', 813), ('understanding', 809), ('question', 786), ('objective', 770), ('natural', 766), ('sein', 743), ('work', 742), ('true', 740), ('nature', 735), ('however', 734), ('rather', 713)]\n",
      "[('one', 5084), ('things', 2930), ('would', 2925), ('say', 2672), ('said', 2331), ('must', 2272), ('good', 2263), ('man', 2179), ('think', 2177), ('us', 2047), ('well', 1983), ('way', 1926), ('socrates', 1866), ('people', 1725), ('thing', 1683), ('like', 1626), ('know', 1495), ('make', 1293), ('something', 1291), ('men', 1230), ('soul', 1202), ('even', 1177), ('also', 1166), ('many', 1129), ('time', 1125), ('let', 1105), ('others', 1071), ('two', 1051), ('right', 1047), ('first', 1027), ('could', 1026), ('see', 1004), ('come', 997), ('whether', 986), ('city', 965), ('knowledge', 963), ('take', 958), ('kind', 919), ('else', 883), ('another', 876), ('since', 874), ('life', 861), ('part', 846), ('gods', 822), ('anyone', 805), ('sort', 797), ('someone', 794), ('anything', 794), ('case', 792), ('give', 784)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('god', 3534), ('one', 2981), ('us', 2594), ('things', 2349), ('mind', 2188), ('would', 2104), ('body', 1829), ('must', 1718), ('nature', 1539), ('even', 1440), ('good', 1396), ('reason', 1391), ('cannot', 1329), ('man', 1319), ('soul', 1297), ('order', 1281), ('without', 1247), ('see', 1211), ('men', 1190), ('idea', 1153), ('bodies', 1126), ('since', 1117), ('cause', 1104), ('know', 1068), ('ideas', 1060), ('therefore', 1023), ('also', 1002), ('thus', 997), ('nothing', 993), ('true', 973), ('certain', 954), ('love', 951), ('motion', 920), ('say', 894), ('always', 841), ('thing', 836), ('make', 828), ('necessary', 813), ('way', 811), ('said', 810), ('may', 790), ('truth', 781), ('first', 781), ('could', 769), ('power', 760), ('far', 757), ('different', 749), ('two', 741), ('knowledge', 735), ('great', 716)]\n",
      "[('thou', 798), ('things', 568), ('unto', 436), ('man', 341), ('thy', 338), ('one', 317), ('thee', 306), ('nature', 272), ('either', 251), ('doth', 247), ('good', 195), ('thyself', 193), ('must', 188), ('whatsoever', 171), ('also', 165), ('world', 156), ('upon', 153), ('shall', 150), ('may', 147), ('mind', 142), ('life', 136), ('hath', 136), ('time', 134), ('men', 132), ('many', 125), ('anything', 124), ('thing', 119), ('another', 119), ('therefore', 118), ('yet', 117), ('part', 116), ('art', 116), ('shalt', 110), ('neither', 106), ('much', 104), ('nothing', 103), ('reason', 103), ('common', 103), ('true', 102), ('let', 101), ('every', 100), ('power', 99), ('proper', 96), ('well', 94), ('according', 87), ('without', 86), ('use', 85), ('say', 83), ('happen', 83), ('hast', 83)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for i in range(len(df1['tokenized_txt'])):\n",
    "    print(Counter([w for w in df1['tokenized_txt'][i] if w.lower() not in stop_words]).most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f90bd",
   "metadata": {},
   "source": [
    "Add most common words that don't tell us anything about the ideas of the school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afc930f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_stopwords = ['called','air','without','one','must','things','also','thing','may','another','case','two','either','first','something','since',\n",
    "'would','therefore','said','many','every','even','eg','possible','cannot','whether','always','number','thus','like','say',\n",
    "                 'well','contrary','cases','neither','yet','point','suppose','really','use','though','particular','general',\n",
    "                 'hence','unto','merely','however','though','ye','thy','hath','thee','among','seems','let','else','if',\n",
    "                 'take','sort','tell','call','go','way','shall','put','say','saying','say','could','although','might','thou',\n",
    "                 'may','doth','dost','according','whatsoever','anything','shalt','indeed','rather','ever','shalt','mayest',\n",
    "                 'much','toward','upon','less']\n",
    "\n",
    "\n",
    "\n",
    "for word in more_stopwords :\n",
    "    stop_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a4addce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_tokens'] = df['tokenized_txt'].apply(lambda x: [w for w in x if w.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81cf013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_dataframe_project1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02fa491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
